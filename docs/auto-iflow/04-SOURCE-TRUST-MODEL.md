# üîç –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è Planning Module

**–¶–µ–ª—å:** –û–±–µ—Å–ø–µ—á–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö, –ø–æ–ª—É—á–∞–µ–º—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫–∞ –≤ –º–æ–¥—É–ª–µ –ö–æ–Ω—Å–∏–ª–∏—É–º–∞.

---

## üéØ –ü—Ä–æ–±–ª–µ–º–∞

–ú–æ–¥—É–ª—å Planning –æ–ø–∏—Ä–∞–µ—Ç—Å—è –Ω–∞ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤, –Ω–æ:

1. –ù–µ –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –æ–¥–∏–Ω–∞–∫–æ–≤–æ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã
2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–µ–π
3. LLM –º–æ–≥—É—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
4. –ù–µ—Ç –º–µ—Ö–∞–Ω–∏–∑–º–∞ –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏

---

## üèó –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Question   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Multi-     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Trust      ‚îÇ
‚îÇ  Generator  ‚îÇ     ‚îÇ  Source     ‚îÇ     ‚îÇ  Scorer     ‚îÇ
‚îÇ             ‚îÇ     ‚îÇ  Search     ‚îÇ     ‚îÇ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Agents     ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Context    ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  Fact       ‚îÇ
‚îÇ  Analysis   ‚îÇ     ‚îÇ  Builder    ‚îÇ     ‚îÇ  Checker    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Trust Score Model

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –æ—Ü–µ–Ω–∫–∏

–ö–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ–ª—É—á–∞–µ—Ç Trust Score –æ—Ç 0.0 –¥–æ 1.0 –Ω–∞ –æ—Å–Ω–æ–≤–µ:

```python
@dataclass
class TrustFactors:
    domain_reputation: float    # 0.0 - 1.0
    source_recency: float       # 0.0 - 1.0
    citation_count: float       # 0.0 - 1.0
    cross_validation: float     # 0.0 - 1.0

def calculate_trust_score(factors: TrustFactors) -> float:
    weights = {
        "domain_reputation": 0.35,
        "source_recency": 0.20,
        "citation_count": 0.15,
        "cross_validation": 0.30
    }
    
    score = (
        factors.domain_reputation * weights["domain_reputation"] +
        factors.source_recency * weights["source_recency"] +
        factors.citation_count * weights["citation_count"] +
        factors.cross_validation * weights["cross_validation"]
    )
    
    return round(score, 2)
```

### 1. Domain Reputation

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ü—Ä–∏–º–µ—Ä—ã | Score |
|-----------|---------|-------|
| **Tier 1** (–ü–µ—Ä–≤–∏—á–Ω—ã–µ) | –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è, –Ω–∞—É—á–Ω—ã–µ –∂—É—Ä–Ω–∞–ª—ã, gov/edu | 0.95 - 1.0 |
| **Tier 2** (–ê–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ) | Gartner, McKinsey, TechCrunch, HBR | 0.80 - 0.94 |
| **Tier 3** (–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ) | Medium (verified), Dev.to, –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–µ –±–ª–æ–≥–∏ | 0.60 - 0.79 |
| **Tier 4** (–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ) | Reddit, StackOverflow, —Ñ–æ—Ä—É–º—ã | 0.40 - 0.59 |
| **Tier 5** (–ù–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ) | –õ–∏—á–Ω—ã–µ –±–ª–æ–≥–∏, —Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏ | 0.20 - 0.39 |
| **Blacklisted** | SEO-—Å–ø–∞–º, —Ñ–µ–π–∫–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ | 0.0 |

```python
DOMAIN_REPUTATION_DB = {
    # Tier 1
    ".gov": 0.95,
    ".edu": 0.95,
    "docs.python.org": 1.0,
    "developer.mozilla.org": 0.98,
    "arxiv.org": 0.95,
    
    # Tier 2
    "gartner.com": 0.90,
    "mckinsey.com": 0.88,
    "techcrunch.com": 0.82,
    "hbr.org": 0.85,
    
    # Tier 3
    "medium.com": 0.65,  # –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∞–≤—Ç–æ—Ä–∞
    "dev.to": 0.60,
    "hashnode.com": 0.58,
    
    # Tier 4
    "reddit.com": 0.50,
    "stackoverflow.com": 0.55,
    "quora.com": 0.45,
    
    # Default
    "_default": 0.40
}
```

### 2. Source Recency

```python
def calculate_recency_score(published_date: datetime) -> float:
    """–ë–æ–ª–µ–µ —Å–≤–µ–∂–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ–ª—É—á–∞—é—Ç –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–π –±–∞–ª–ª"""
    age_days = (datetime.utcnow() - published_date).days
    
    if age_days <= 30:
        return 1.0
    elif age_days <= 90:
        return 0.9
    elif age_days <= 180:
        return 0.8
    elif age_days <= 365:
        return 0.6
    elif age_days <= 730:  # 2 years
        return 0.4
    else:
        return 0.2
```

### 3. Citation Count

```python
def calculate_citation_score(citation_count: int, domain_type: str) -> float:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –±–∞–ª–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–π"""
    
    # –†–∞–∑–Ω—ã–µ thresholds –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    thresholds = {
        "academic": {"high": 100, "medium": 20},
        "blog": {"high": 1000, "medium": 100},
        "forum": {"high": 500, "medium": 50}
    }
    
    t = thresholds.get(domain_type, thresholds["blog"])
    
    if citation_count >= t["high"]:
        return 1.0
    elif citation_count >= t["medium"]:
        return 0.7
    elif citation_count > 0:
        return 0.4
    else:
        return 0.2
```

### 4. Cross-Validation Score

```python
async def calculate_cross_validation_score(
    claim: str,
    sources: List[SearchResult]
) -> float:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –ª–∏ claim –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    
    confirming_sources = 0
    contradicting_sources = 0
    
    for source in sources:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º LLM –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
        result = await verify_claim_against_source(claim, source)
        
        if result == "confirms":
            confirming_sources += 1
        elif result == "contradicts":
            contradicting_sources += 1
    
    if contradicting_sources >= 2:
        return 0.0  # –Ø–≤–Ω–æ–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ
    
    # –¢—Ä–µ–±—É–µ–º –º–∏–Ω–∏–º—É–º 2 –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    if confirming_sources >= 3:
        return 1.0
    elif confirming_sources >= 2:
        return 0.8
    elif confirming_sources >= 1:
        return 0.5
    else:
        return 0.3  # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
```

---

## üîÑ –ü–æ–ª–∏—Ç–∏–∫–∞ –ø–æ–∏—Å–∫–∞

### –ú–∏–Ω–∏–º—É–º 2 –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞

```python
@dataclass
class SearchPolicy:
    min_sources: int = 2
    max_sources: int = 5
    min_trust_score: float = 0.5
    require_tier1_or_tier2: bool = True
    max_same_domain_sources: int = 2
    
async def search_with_policy(
    query: str,
    policy: SearchPolicy
) -> List[VerifiedSource]:
    """–ü–æ–∏—Å–∫ —Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç–∏"""
    
    # –®–∞–≥ 1: –ü–æ–ª—É—á–∞–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–∏—Å—Ç–µ–º
    candidates = []
    
    async with asyncio.TaskGroup() as tg:
        # Perplexity API
        perplexity_task = tg.create_task(search_perplexity(query))
        # Tavily API (fallback)
        tavily_task = tg.create_task(search_tavily(query))
    
    candidates.extend(perplexity_task.result())
    candidates.extend(tavily_task.result())
    
    # –®–∞–≥ 2: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
    unique_candidates = deduplicate_by_url(candidates)
    
    # –®–∞–≥ 3: –û—Ü–µ–Ω–∫–∞ Trust Score
    scored_candidates = []
    for candidate in unique_candidates:
        trust_score = await calculate_full_trust_score(candidate)
        if trust_score >= policy.min_trust_score:
            scored_candidates.append((candidate, trust_score))
    
    # –®–∞–≥ 4: –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ Trust Score
    scored_candidates.sort(key=lambda x: x[1], reverse=True)
    
    # –®–∞–≥ 5: –í—ã–±–æ—Ä —Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º diversity
    selected = []
    domain_counts = defaultdict(int)
    has_tier1_or_tier2 = False
    
    for candidate, score in scored_candidates:
        domain = get_base_domain(candidate.url)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –Ω–∞ –¥–æ–º–µ–Ω
        if domain_counts[domain] >= policy.max_same_domain_sources:
            continue
        
        selected.append(VerifiedSource(
            source=candidate,
            trust_score=score,
            verification_tag=get_verification_tag(score)
        ))
        domain_counts[domain] += 1
        
        if score >= 0.8:
            has_tier1_or_tier2 = True
        
        if len(selected) >= policy.max_sources:
            break
    
    # –®–∞–≥ 6: –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ–ª–∏—Ç–∏–∫–∏
    if len(selected) < policy.min_sources:
        raise InsufficientSourcesError(
            f"Found only {len(selected)} sources, need {policy.min_sources}"
        )
    
    if policy.require_tier1_or_tier2 and not has_tier1_or_tier2:
        raise NoAuthoritySourceError(
            "No Tier 1 or Tier 2 sources found"
        )
    
    return selected
```

---

## üè∑ Verification Tags

–ö–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ–ª—É—á–∞–µ—Ç –≤–∏–∑—É–∞–ª—å–Ω—ã–π —Ç–µ–≥ –¥–ª—è UI:

| Tag | Trust Score | Emoji | –ó–Ω–∞—á–µ–Ω–∏–µ |
|-----|-------------|-------|----------|
| `VERIFIED` | ‚â• 0.85 | ‚úÖ | –í—ã—Å–æ–∫–æ–¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ |
| `TRUSTED` | 0.70 - 0.84 | üü¢ | –î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ |
| `MODERATE` | 0.50 - 0.69 | üü° | –£–º–µ—Ä–µ–Ω–Ω–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å |
| `LOW` | 0.30 - 0.49 | üü† | –ù–∏–∑–∫–∞—è –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å |
| `UNVERIFIED` | < 0.30 | üî¥ | –ù–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ |

```python
def get_verification_tag(trust_score: float) -> VerificationTag:
    if trust_score >= 0.85:
        return VerificationTag.VERIFIED
    elif trust_score >= 0.70:
        return VerificationTag.TRUSTED
    elif trust_score >= 0.50:
        return VerificationTag.MODERATE
    elif trust_score >= 0.30:
        return VerificationTag.LOW
    else:
        return VerificationTag.UNVERIFIED
```

---

## üõ° –ê–Ω—Ç–∏-–≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ä—ã

### 1. Explicit Grounding

```python
GROUNDING_PROMPT = """
You are analyzing information from external sources. Follow these rules:

1. ONLY use information that is EXPLICITLY stated in the provided sources
2. DO NOT infer or extrapolate beyond what sources say
3. If sources disagree, note the contradiction explicitly
4. If no source covers a topic, say "No data available from sources"
5. Always cite the specific source for each claim using [Source N] format

Sources:
{sources}

Question: {question}

Provide your analysis, citing sources for every factual claim.
"""
```

### 2. Confidence Calibration

```python
@dataclass
class AnalysisResult:
    content: str
    confidence: float  # 0.0 - 1.0
    source_coverage: float  # % –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–∫—Ä—ã—Ç–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    contradictions: List[str]

async def analyze_with_confidence(
    question: str,
    sources: List[VerifiedSource],
    agent_role: str
) -> AnalysisResult:
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Å explicit grounding
    response = await llm.generate(
        GROUNDING_PROMPT.format(
            sources=format_sources(sources),
            question=question
        ),
        system_prompt=AGENT_PROMPTS[agent_role]
    )
    
    # –û—Ü–µ–Ω–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏
    source_coverage = calculate_source_coverage(question, sources, response)
    
    # –ü–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π
    contradictions = detect_contradictions(sources)
    
    # –†–∞—Å—á–µ—Ç confidence
    avg_trust = sum(s.trust_score for s in sources) / len(sources)
    confidence = avg_trust * source_coverage * (1 - 0.2 * len(contradictions))
    
    return AnalysisResult(
        content=response,
        confidence=confidence,
        source_coverage=source_coverage,
        contradictions=contradictions
    )
```

### 3. Fact Extraction & Verification

```python
async def extract_and_verify_facts(
    analysis: str,
    sources: List[VerifiedSource]
) -> List[VerifiedFact]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Ö –ø—Ä–æ—Ç–∏–≤ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã
    facts = await extract_facts(analysis)
    
    verified_facts = []
    for fact in facts:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–∫—Ç
        verification = await verify_fact_against_sources(fact, sources)
        
        verified_facts.append(VerifiedFact(
            statement=fact.statement,
            source_references=verification.sources,
            verified=verification.is_verified,
            confidence=verification.confidence,
            contradicting_sources=verification.contradictions
        ))
    
    return verified_facts
```

### 4. Contradiction Detection

```python
async def detect_contradictions(
    sources: List[VerifiedSource]
) -> List[Contradiction]:
    """–ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"""
    
    contradictions = []
    
    for i, source_a in enumerate(sources):
        for source_b in sources[i+1:]:
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—É—é –ø–∞—Ä—É
            result = await compare_sources_for_contradictions(source_a, source_b)
            
            if result.has_contradiction:
                contradictions.append(Contradiction(
                    source_a=source_a.url,
                    source_b=source_b.url,
                    claim_a=result.claim_a,
                    claim_b=result.claim_b,
                    topic=result.topic
                ))
    
    return contradictions
```

---

## üìä UI Presentation

### Source Card Format

```markdown
### üì∞ Market Size Analysis

**Source 1:** [Gartner Report 2025](https://gartner.com/...) ‚úÖ VERIFIED
> "The global AI market is projected to reach $407B by 2027..."
- Trust Score: 0.92
- Published: Jan 2025
- Cross-validated: 3 other sources

**Source 2:** [TechCrunch Analysis](https://techcrunch.com/...) üü¢ TRUSTED
> "AI startup funding increased 15% YoY..."
- Trust Score: 0.78
- Published: Dec 2025
- Cross-validated: 2 other sources

‚ö†Ô∏è **Note:** Sources disagree on growth rate (Gartner: 25%, TechCrunch: 15%)
```

### Confidence Indicator

```markdown
## Analysis Confidence

| Metric | Value |
|--------|-------|
| Overall confidence | üü¢ 82% |
| Source coverage | 95% |
| Contradictions | 1 minor |
| Verification tags | 2 ‚úÖ, 1 üü¢, 0 üü° |
```

---

## ‚úÖ Checklist –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞

- [ ] –ú–∏–Ω–∏–º—É–º 2 –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞
- [ ] –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã 1 –∏—Å—Ç–æ—á–Ω–∏–∫ Tier 1-2
- [ ] –ù–µ—Ç –±–æ–ª–µ–µ 2 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å –æ–¥–Ω–æ–≥–æ –¥–æ–º–µ–Ω–∞
- [ ] –í—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–º–µ—é—Ç trust score ‚â• 0.5
- [ ] –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∑–∞–¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω—ã
- [ ] –ö–∞–∂–¥—ã–π —Ñ–∞–∫—Ç –ø—Ä–∏–≤—è–∑–∞–Ω –∫ –∏—Å—Ç–æ—á–Ω–∏–∫—É
- [ ] Confidence score —Ä–∞—Å—Å—á–∏—Ç–∞–Ω –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω
