# üß™ –°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**–¶–µ–ª—å:** –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞ –∏ —Å—Ü–µ–Ω–∞—Ä–∏–∏ –Ω–∞–≥—Ä—É–∑–æ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.

---

## üìä –ü–∏—Ä–∞–º–∏–¥–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   E2E Tests     ‚îÇ  ‚Üê 5-10 —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤
                    ‚îÇ   (Playwright)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Integration    ‚îÇ  ‚Üê 20-30 —Ç–µ—Å—Ç–æ–≤
                    ‚îÇ  Tests          ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ         Unit Tests                ‚îÇ  ‚Üê 100+ —Ç–µ—Å—Ç–æ–≤
           ‚îÇ      (pytest, >80% coverage)      ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚úÖ –ö—Ä–∏—Ç–µ—Ä–∏–∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ (Definition of Done)

### Phase 0: Research & PoC

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ú–µ—Ç—Ä–∏–∫–∞ | –ü—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª |
|----------|---------|----------------|
| SDK —Ä–∞–±–æ—Ç–∞–µ—Ç | hello_agent.py —É—Å–ø–µ—à–µ–Ω | ‚úÖ Pass |
| –°–æ–±—ã—Ç–∏—è –ø—Ä–∏—Ö–æ–¥—è—Ç | –í—Å–µ 4 —Ç–∏–ø–∞ —Å–æ–±—ã—Ç–∏–π –ø–æ–ª—É—á–µ–Ω—ã | ‚â• 3 —Ç–∏–ø–∞ |
| –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º | 12 –∞–≥–µ–Ω—Ç–æ–≤ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ | ‚â• 8 –∞–≥–µ–Ω—Ç–æ–≤ |
| –ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Ç–µ—Å—Ç | –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–æ–≤ | ‚â• 80% |
| –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è | Technical Spike report | ‚úÖ –°–æ–∑–¥–∞–Ω |

### Phase 1: Core Migration

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ú–µ—Ç—Ä–∏–∫–∞ | –ü—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª |
|----------|---------|----------------|
| IFlowWrapper | Unit tests pass | ‚â• 90% |
| Single agent | –°–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª, –∫–æ–º–º–∏—Ç–∏—Ç | ‚úÖ Pass |
| Multi-agent | 12 –∞–≥–µ–Ω—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ | ‚â• 10 –∞–≥–µ–Ω—Ç–æ–≤ |
| Event streaming | UI –ø–æ–ª—É—á–∞–µ—Ç events | Latency < 500ms |
| Worktree isolation | –ù–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ | 0 –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ |
| Git operations | Merge –±–µ–∑ –æ—à–∏–±–æ–∫ | ‚â• 95% |
| Unit test coverage | Backend coverage | ‚â• 80% |

### Phase 2: Planning Module

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ú–µ—Ç—Ä–∏–∫–∞ | –ü—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª |
|----------|---------|----------------|
| 3-agent council | –í—Å–µ —Ä–æ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç | ‚úÖ All 3 |
| Search integration | –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–∏—Ö–æ–¥—è—Ç | Avg < 3s |
| Source verification | Trust scores calculated | ‚úÖ Pass |
| Interview flow | 8 –≤–æ–ø—Ä–æ—Å–æ–≤ –∑–∞–¥–∞–Ω–æ | ‚úÖ All 8 |
| Concept generation | concept.md —Å–æ–∑–¥–∞–Ω | ‚úÖ Valid format |
| Anti-hallucination | Facts grounded | ‚â• 90% grounded |
| Unit test coverage | Planning module | ‚â• 85% |

### Phase 3: Integration & Polish

| –ö—Ä–∏—Ç–µ—Ä–∏–π | –ú–µ—Ç—Ä–∏–∫–∞ | –ü—Ä–æ—Ö–æ–¥–Ω–æ–π –±–∞–ª–ª |
|----------|---------|----------------|
| UI Planning tab | Renders correctly | ‚úÖ Pass |
| Event visualization | 3 —Ü–≤–µ—Ç–∞ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ | ‚úÖ Pass |
| Full E2E flow | Idea ‚Üí concept.md ‚Üí tasks.json ‚Üí code | ‚úÖ Pass |
| Performance | Full cycle < 30 min | ‚â§ 30 min |
| Error handling | Graceful degradation | No crashes |
| Documentation | User guide created | ‚úÖ Pass |

---

## üî¨ Unit Tests

### Backend Tests Structure

```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_iflow_wrapper.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_orchestrator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_event_bus.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_session_manager.py
‚îÇ   ‚îú‚îÄ‚îÄ planning/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_brainstorming_module.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_search_adapter.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_trust_scorer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_fact_checker.py
‚îÇ   ‚îú‚îÄ‚îÄ security/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_tool_validator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_sandbox.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_security_logger.py
‚îÇ   ‚îî‚îÄ‚îÄ storage/
‚îÇ       ‚îú‚îÄ‚îÄ test_session_db.py
‚îÇ       ‚îú‚îÄ‚îÄ test_event_log.py
‚îÇ       ‚îî‚îÄ‚îÄ test_artifact_store.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_full_agent_cycle.py
‚îÇ   ‚îú‚îÄ‚îÄ test_multi_agent_orchestration.py
‚îÇ   ‚îú‚îÄ‚îÄ test_planning_flow.py
‚îÇ   ‚îî‚îÄ‚îÄ test_git_operations.py
‚îî‚îÄ‚îÄ e2e/
    ‚îú‚îÄ‚îÄ test_complete_workflow.py
    ‚îî‚îÄ‚îÄ test_ui_interactions.py
```

### Example Unit Tests

```python
# tests/unit/core/test_iflow_wrapper.py
import pytest
from unittest.mock import AsyncMock, MagicMock
from auto_iflow.core.iflow_wrapper import IFlowWrapper, IFlowConfig

class TestIFlowWrapper:
    
    @pytest.fixture
    def wrapper(self):
        config = IFlowConfig(
            approval_mode="AUTO_EDIT",
            working_directory="/tmp/test"
        )
        return IFlowWrapper(config)
    
    @pytest.mark.asyncio
    async def test_send_message_returns_events(self, wrapper):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ send_message –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è"""
        wrapper._client = AsyncMock()
        wrapper._client.query.return_value = [
            MagicMock(content="Hello"),
            MagicMock(tool_name="write_file", args={"path": "test.py"})
        ]
        
        events = []
        async for event in wrapper.send_message("Create a file"):
            events.append(event)
        
        assert len(events) == 2
        assert events[0].content == "Hello"
    
    @pytest.mark.asyncio
    async def test_handles_connection_error(self, wrapper):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è"""
        wrapper._client = AsyncMock()
        wrapper._client.query.side_effect = ConnectionError("Failed to connect")
        
        with pytest.raises(IFlowConnectionError):
            async for _ in wrapper.send_message("Test"):
                pass
    
    @pytest.mark.asyncio
    async def test_cleanup_on_context_exit(self, wrapper):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–∏—Å—Ç–∫—É —Ä–µ—Å—É—Ä—Å–æ–≤"""
        wrapper._client = AsyncMock()
        
        async with wrapper:
            pass
        
        wrapper._client.close.assert_called_once()


# tests/unit/security/test_tool_validator.py
import pytest
from auto_iflow.security.tool_validator import ToolValidator, SecurityConfig

class TestToolValidator:
    
    @pytest.fixture
    def validator(self):
        config = SecurityConfig(
            blocked_patterns=["rm -rf", "sudo"],
            allowed_commands=["python", "pip", "git"],
            blocked_paths=[".env", "*.pem"]
        )
        return ToolValidator(config)
    
    def test_blocks_dangerous_command(self, validator):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –æ–ø–∞—Å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥"""
        result = validator.validate_tool_call(
            tool_name="execute",
            args={"command": "rm -rf /"},
            approval_mode="YOLO"
        )
        
        assert result.allowed is False
        assert "blocked pattern" in result.reason.lower()
    
    def test_allows_safe_command(self, validator):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥"""
        result = validator.validate_tool_call(
            tool_name="execute",
            args={"command": "python test.py"},
            approval_mode="AUTO_EDIT"
        )
        
        assert result.allowed is True
    
    def test_blocks_write_to_env_file(self, validator):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –∑–∞–ø–∏—Å–∏ –≤ .env"""
        result = validator.validate_tool_call(
            tool_name="write_file",
            args={"path": "/project/.env"},
            approval_mode="YOLO"
        )
        
        assert result.allowed is False


# tests/unit/planning/test_trust_scorer.py
import pytest
from datetime import datetime, timedelta
from auto_iflow.planning.trust_scorer import TrustScorer, SearchResult

class TestTrustScorer:
    
    @pytest.fixture
    def scorer(self):
        return TrustScorer()
    
    def test_official_docs_get_high_score(self, scorer):
        """–û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø–æ–ª—É—á–∞—Ç—å –≤—ã—Å–æ–∫–∏–π –±–∞–ª–ª"""
        result = SearchResult(
            url="https://docs.python.org/3/tutorial/",
            published_date=datetime.utcnow(),
            citation_count=1000
        )
        
        score = scorer.calculate_trust_score(result)
        
        assert score >= 0.90
    
    def test_old_sources_get_lower_score(self, scorer):
        """–°—Ç–∞—Ä—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∞—Ç—å –±–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –±–∞–ª–ª"""
        recent = SearchResult(
            url="https://example.com/article",
            published_date=datetime.utcnow() - timedelta(days=30),
            citation_count=100
        )
        
        old = SearchResult(
            url="https://example.com/old-article",
            published_date=datetime.utcnow() - timedelta(days=730),
            citation_count=100
        )
        
        recent_score = scorer.calculate_trust_score(recent)
        old_score = scorer.calculate_trust_score(old)
        
        assert recent_score > old_score
```

---

## üîó Integration Tests

```python
# tests/integration/test_full_agent_cycle.py
import pytest
import tempfile
import shutil
from pathlib import Path
from auto_iflow.core import Orchestrator, SessionConfig

class TestFullAgentCycle:
    
    @pytest.fixture
    def temp_project(self):
        """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –¥–ª—è —Ç–µ—Å—Ç–∞"""
        temp_dir = Path(tempfile.mkdtemp())
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º git
        subprocess.run(["git", "init"], cwd=temp_dir, check=True)
        subprocess.run(["git", "config", "user.email", "test@test.com"], cwd=temp_dir)
        subprocess.run(["git", "config", "user.name", "Test"], cwd=temp_dir)
        
        # –°–æ–∑–¥–∞–µ–º initial commit
        (temp_dir / "README.md").write_text("# Test Project")
        subprocess.run(["git", "add", "."], cwd=temp_dir)
        subprocess.run(["git", "commit", "-m", "Initial"], cwd=temp_dir)
        
        yield temp_dir
        
        shutil.rmtree(temp_dir)
    
    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_single_agent_creates_file(self, temp_project):
        """–û–¥–∏–Ω –∞–≥–µ–Ω—Ç —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª –∏ –∫–æ–º–º–∏—Ç–∏—Ç"""
        config = SessionConfig(
            project_path=temp_project,
            max_agents=1,
            approval_mode="YOLO"
        )
        
        orchestrator = Orchestrator(config)
        
        async with orchestrator:
            result = await orchestrator.run_task(
                "Create a Python file called hello.py with a hello_world function"
            )
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω
        hello_py = temp_project / "hello.py"
        assert hello_py.exists()
        
        content = hello_py.read_text()
        assert "def hello_world" in content
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –∫–æ–º–º–∏—Ç
        log = subprocess.run(
            ["git", "log", "--oneline"],
            cwd=temp_project,
            capture_output=True,
            text=True
        )
        assert len(log.stdout.strip().split("\n")) > 1


# tests/integration/test_multi_agent_orchestration.py
@pytest.mark.asyncio
@pytest.mark.integration
async def test_12_agents_parallel_no_conflicts(temp_project):
    """12 –∞–≥–µ–Ω—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –±–µ–∑ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤"""
    config = SessionConfig(
        project_path=temp_project,
        max_agents=12,
        approval_mode="YOLO"
    )
    
    orchestrator = Orchestrator(config)
    
    tasks = [
        f"Create a Python module called module_{i}.py with a function func_{i}"
        for i in range(12)
    ]
    
    async with orchestrator:
        results = await orchestrator.run_parallel_tasks(tasks)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ 12 —Ñ–∞–π–ª–æ–≤ —Å–æ–∑–¥–∞–Ω—ã
    for i in range(12):
        module_file = temp_project / f"module_{i}.py"
        assert module_file.exists(), f"module_{i}.py not found"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –Ω–µ—Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
    status = subprocess.run(
        ["git", "status", "--porcelain"],
        cwd=temp_project,
        capture_output=True,
        text=True
    )
    assert "UU" not in status.stdout  # UU = unmerged


# tests/integration/test_planning_flow.py
@pytest.mark.asyncio
@pytest.mark.integration
async def test_planning_generates_concept_md(temp_project):
    """Planning module –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç concept.md"""
    config = PlanningConfig(
        project_path=temp_project,
        search_enabled=True,
        min_sources=2
    )
    
    planning = BrainstormingModule(config)
    
    # –°–∏–º—É–ª–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    answers = [
        "A task management app for developers",
        "Existing tools are too complex",
        "Global, starting with English-speaking markets",
        "MVP in 3 months",
        "1000 daily active users in 6 months",
        "Individual developers and small teams",
        "Sign up -> Create project -> Add tasks -> Track progress",
        "Simple, fast, and developer-focused"
    ]
    
    result = await planning.run_interview(answers)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ concept.md —Å–æ–∑–¥–∞–Ω
    concept_file = temp_project / ".iflow" / "docs" / "concept.md"
    assert concept_file.exists()
    
    content = concept_file.read_text()
    assert "## Executive Summary" in content
    assert "## Target Audience" in content
    assert "## Value Proposition" in content
```

---

## üöÄ E2E Tests

```python
# tests/e2e/test_complete_workflow.py
import pytest
from playwright.async_api import async_playwright

class TestCompleteWorkflow:
    
    @pytest.fixture
    async def app(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç Electron –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"""
        async with async_playwright() as p:
            # –ó–∞–ø—É—Å–∫–∞–µ–º Electron
            app = await p.electron.launch(
                args=["./apps/frontend/dist/main.js"]
            )
            yield app
            await app.close()
    
    @pytest.mark.asyncio
    @pytest.mark.e2e
    async def test_full_planning_to_code_cycle(self, app, temp_project):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª: –∏–¥–µ—è -> –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ -> –∫–æ–¥"""
        
        window = await app.first_window()
        
        # 1. –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–µ–∫—Ç
        await window.click('[data-testid="open-project"]')
        await window.fill('[data-testid="project-path"]', str(temp_project))
        await window.click('[data-testid="confirm-open"]')
        
        # 2. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –≤–∫–ª–∞–¥–∫—É Planning
        await window.click('[data-testid="tab-planning"]')
        
        # 3. –ù–∞—á–∏–Ω–∞–µ–º –∏–Ω—Ç–µ—Ä–≤—å—é
        await window.click('[data-testid="start-interview"]')
        
        # 4. –û—Ç–≤–µ—á–∞–µ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
        questions_count = 8
        for i in range(questions_count):
            await window.wait_for_selector(f'[data-testid="question-{i}"]')
            await window.fill(
                '[data-testid="answer-input"]',
                f"Test answer for question {i}"
            )
            await window.click('[data-testid="submit-answer"]')
        
        # 5. –ñ–¥–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ concept.md
        await window.wait_for_selector('[data-testid="concept-ready"]', timeout=60000)
        
        # 6. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∞–≥–µ–Ω—Ç—ã –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ –º–Ω–µ–Ω–∏—è
        innovator = await window.text_content('[data-testid="innovator-opinion"]')
        realist = await window.text_content('[data-testid="realist-opinion"]')
        facilitator = await window.text_content('[data-testid="facilitator-opinion"]')
        
        assert len(innovator) > 100
        assert len(realist) > 100
        assert len(facilitator) > 100
        
        # 7. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º tasks.json
        await window.click('[data-testid="generate-tasks"]')
        await window.wait_for_selector('[data-testid="tasks-ready"]')
        
        # 8. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ Execution
        await window.click('[data-testid="tab-execution"]')
        
        # 9. –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤
        await window.click('[data-testid="start-execution"]')
        
        # 10. –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (—Å –±–æ–ª—å—à–∏–º timeout)
        await window.wait_for_selector(
            '[data-testid="execution-complete"]',
            timeout=300000  # 5 minutes
        )
        
        # 11. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–æ–¥ —Å–æ–∑–¥–∞–Ω
        files_created = await window.text_content('[data-testid="files-created-count"]')
        assert int(files_created) > 0
```

---

## üìä –ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π: 12 –∞–≥–µ–Ω—Ç–æ–≤ √ó 3 –∏—Ç–µ—Ä–∞—Ü–∏–∏

```python
# tests/load/test_parallel_agents_stress.py
import asyncio
import time
import json
from dataclasses import dataclass, asdict
from typing import List
from pathlib import Path

@dataclass
class LoadTestMetrics:
    total_agents: int
    total_iterations: int
    successful: int
    failed: int
    avg_duration_ms: float
    max_duration_ms: float
    min_duration_ms: float
    p95_duration_ms: float
    p99_duration_ms: float
    total_messages: int
    errors: List[str]
    timestamp: str

async def run_load_test(
    num_agents: int = 12,
    iterations: int = 3,
    output_dir: Path = Path("./test_reports")
) -> LoadTestMetrics:
    """
    –ù–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Ç–µ—Å—Ç: N –∞–≥–µ–Ω—Ç–æ–≤ √ó M –∏—Ç–µ—Ä–∞—Ü–∏–π
    
    –ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:
    - –£—Å–ø–µ—à–Ω–æ—Å—Ç—å ‚â• 80%
    - P95 latency < 60s
    - –ù–µ—Ç memory leaks
    - –ù–µ—Ç deadlocks
    """
    
    all_results = []
    
    for iteration in range(iterations):
        print(f"\nüîÑ Iteration {iteration + 1}/{iterations}")
        
        # –°–æ–∑–¥–∞–µ–º –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        workdirs = [
            Path(f"/tmp/load_test/iter_{iteration}/agent_{i}")
            for i in range(num_agents)
        ]
        
        for wd in workdirs:
            wd.mkdir(parents=True, exist_ok=True)
            # Git init
            subprocess.run(["git", "init"], cwd=wd, capture_output=True)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [
            run_single_agent_with_metrics(i, workdirs[i], LOAD_TEST_TASKS[i % len(LOAD_TEST_TASKS)])
            for i in range(num_agents)
        ]
        
        start_time = time.time()
        results = await asyncio.gather(*tasks, return_exceptions=True)
        iteration_time = time.time() - start_time
        
        print(f"   Iteration time: {iteration_time:.2f}s")
        all_results.extend(results)
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = aggregate_metrics(all_results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    output_dir.mkdir(parents=True, exist_ok=True)
    report_path = output_dir / f"load_test_{int(time.time())}.json"
    
    with open(report_path, "w") as f:
        json.dump(asdict(metrics), f, indent=2)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º markdown –æ—Ç—á–µ—Ç
    generate_markdown_report(metrics, output_dir / "load_test_report.md")
    
    return metrics

def aggregate_metrics(results: List) -> LoadTestMetrics:
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ç–µ—Å—Ç–æ–≤"""
    
    successful = [r for r in results if isinstance(r, AgentResult) and r.success]
    failed = [r for r in results if not isinstance(r, AgentResult) or not r.success]
    
    durations = sorted([r.duration_ms for r in successful])
    
    return LoadTestMetrics(
        total_agents=len(results),
        total_iterations=3,
        successful=len(successful),
        failed=len(failed),
        avg_duration_ms=sum(durations) / len(durations) if durations else 0,
        max_duration_ms=max(durations) if durations else 0,
        min_duration_ms=min(durations) if durations else 0,
        p95_duration_ms=durations[int(len(durations) * 0.95)] if durations else 0,
        p99_duration_ms=durations[int(len(durations) * 0.99)] if durations else 0,
        total_messages=sum(r.messages_count for r in successful),
        errors=[str(r) for r in failed][:10],  # First 10 errors
        timestamp=datetime.utcnow().isoformat()
    )

LOAD_TEST_TASKS = [
    "Create a Python function that calculates fibonacci numbers recursively",
    "Create a simple REST API endpoint using FastAPI",
    "Write pytest unit tests for a Calculator class",
    "Create a YAML configuration parser",
    "Implement a memoization decorator",
    "Create a rotating file logger",
    "Write a file watcher using watchdog",
    "Implement exponential backoff retry decorator",
    "Create a simple finite state machine",
    "Write a JSON schema validator",
    "Create a CLI argument parser using argparse",
    "Implement a simple in-memory LRU cache"
]

# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
if __name__ == "__main__":
    metrics = asyncio.run(run_load_test(num_agents=12, iterations=3))
    
    print(f"\nüìä Load Test Summary:")
    print(f"   Success rate: {metrics.successful}/{metrics.total_agents} ({metrics.successful/metrics.total_agents*100:.1f}%)")
    print(f"   Avg duration: {metrics.avg_duration_ms:.0f}ms")
    print(f"   P95 duration: {metrics.p95_duration_ms:.0f}ms")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    assert metrics.successful / metrics.total_agents >= 0.8, "Success rate < 80%"
    assert metrics.p95_duration_ms < 60000, "P95 latency > 60s"
```

---

## üìù Test Report Template

```markdown
# üß™ Load Test Report

**Date:** {{ timestamp }}
**Configuration:** {{ num_agents }} agents √ó {{ iterations }} iterations

## Summary

| Metric | Value | Status |
|--------|-------|--------|
| Success Rate | {{ success_rate }}% | {{ "‚úÖ" if success_rate >= 80 else "‚ùå" }} |
| Avg Duration | {{ avg_duration }}ms | {{ "‚úÖ" if avg_duration < 30000 else "‚ö†Ô∏è" }} |
| P95 Duration | {{ p95_duration }}ms | {{ "‚úÖ" if p95_duration < 60000 else "‚ùå" }} |
| Total Messages | {{ total_messages }} | - |

## Timing Distribution

```

     Min   P50   P75   P95   P99   Max
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
     {{ min }}ms  {{ p50 }}ms  {{ p75 }}ms  {{ p95 }}ms  {{ p99 }}ms  {{ max }}ms

```

## Errors (Top 10)

{{ errors_table }}

## Recommendations

{{ recommendations }}
```

---

## ‚úÖ Test Coverage Requirements

| Module | Minimum Coverage | Target Coverage |
|--------|-----------------|-----------------|
| `core/` | 80% | 90% |
| `planning/` | 85% | 95% |
| `security/` | 90% | 98% |
| `storage/` | 75% | 85% |
| **Total** | **80%** | **90%** |

### Running Coverage

```bash
# Run with coverage
pytest --cov=auto_iflow --cov-report=html --cov-fail-under=80

# Generate badge
coverage-badge -o coverage.svg
```
